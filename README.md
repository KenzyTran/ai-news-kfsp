# AI News Summarizer API

API t√≥m t·∫Øt tin t·ª©c s·ª≠ d·ª•ng AI (Ollama) v·ªõi FastAPI.

## üöÄ T√≠nh nƒÉng

- API REST ƒë·ªÉ t√≥m t·∫Øt tin t·ª©c
- H·ªó tr·ª£ ti·∫øng Vi·ªát v√† ti·∫øng Anh
- Ki·ªÉm tra s·ª©c kh·ªèe h·ªá th·ªëng
- T√πy ch·ªânh ƒë·ªô d√†i t√≥m t·∫Øt
- Ready for production deployment

## üìã API Endpoints

### GET /
Th√¥ng tin c∆° b·∫£n v·ªÅ API

### GET /health
Ki·ªÉm tra tr·∫°ng th√°i API v√† k·∫øt n·ªëi Ollama

### POST /summarize
T√≥m t·∫Øt tin t·ª©c

**Request Body:**
```json
{
  "text": "N·ªôi dung tin t·ª©c c·∫ßn t√≥m t·∫Øt...",
  "max_words": 50,
  "language": "vietnamese"
}
```

**Response:**
```json
{
  "summary": "T√≥m t·∫Øt tin t·ª©c...",
  "original_length": 500,
  "summary_length": 45,
  "status": "success"
}
```

### GET /models
Th√¥ng tin v·ªÅ model ƒëang s·ª≠ d·ª•ng

## üõ†Ô∏è C√†i ƒë·∫∑t v√† ch·∫°y

### 1. Development
```bash
# C√†i ƒë·∫∑t dependencies
pip install -r requirements.txt

# Ch·∫°y API
python api.py
```

### 2. Production v·ªõi Docker
```bash
# Build v√† ch·∫°y
docker-compose up -d

# Ho·∫∑c ch·ªâ build API (n·∫øu ƒë√£ c√≥ Ollama)
docker build -t ai-news-api .
docker run -p 8000:8000 -e OLLAMA_BASE_URL=http://your-ollama-server:11434/v1 ai-news-api
```

### 3. Production v·ªõi Gunicorn
```bash
# C√†i th√™m gunicorn
pip install gunicorn

# Ch·∫°y v·ªõi gunicorn
bash start_production.sh
```

## üîß C·∫•u h√¨nh

### Bi·∫øn m√¥i tr∆∞·ªùng:
- `OLLAMA_BASE_URL`: URL c·ªßa Ollama server (m·∫∑c ƒë·ªãnh: http://localhost:11434/v1)
- `OLLAMA_MODEL`: T√™n model s·ª≠ d·ª•ng (m·∫∑c ƒë·ªãnh: qwen2.5:0.5b)
- `OLLAMA_API_KEY`: API key cho Ollama (m·∫∑c ƒë·ªãnh: 123)
- `HOST`: Host bind (m·∫∑c ƒë·ªãnh: 0.0.0.0)
- `PORT`: Port (m·∫∑c ƒë·ªãnh: 8000)

### File .env:
```bash
cp .env.example .env
# Ch·ªânh s·ª≠a .env v·ªõi th√¥ng tin c·ªßa b·∫°n
```

## üìö S·ª≠ d·ª•ng API

### cURL example:
```bash
curl -X POST "http://localhost:8000/summarize" \
     -H "Content-Type: application/json" \
     -d '{
       "text": "ƒê√¢y l√† n·ªôi dung tin t·ª©c c·∫ßn t√≥m t·∫Øt...",
       "max_words": 30,
       "language": "vietnamese"
     }'
```

### Python example:
```python
import requests

response = requests.post(
    "http://localhost:8000/summarize",
    json={
        "text": "N·ªôi dung tin t·ª©c...",
        "max_words": 50,
        "language": "vietnamese"
    }
)

result = response.json()
print(result["summary"])
```

### JavaScript example:
```javascript
const response = await fetch('http://localhost:8000/summarize', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    text: 'N·ªôi dung tin t·ª©c...',
    max_words: 50,
    language: 'vietnamese'
  })
});

const result = await response.json();
console.log(result.summary);
```

## üöÄ Deployment

### 1. VPS/Server truy·ªÅn th·ªëng:
```bash
# Clone repository
git clone <your-repo>
cd ai-news-kfsp

# C√†i ƒë·∫∑t Python dependencies
pip install -r requirements.txt

# C√†i ƒë·∫∑t v√† ch·∫°y Ollama
curl -fsSL https://ollama.ai/install.sh | sh
ollama serve &
ollama pull qwen2.5:0.5b

# Ch·∫°y API
python api.py
```

### 2. Cloud platforms:
- **Heroku**: S·ª≠ d·ª•ng Procfile
- **Railway**: Deploy tr·ª±c ti·∫øp t·ª´ GitHub
- **DigitalOcean App Platform**: S·ª≠ d·ª•ng Docker
- **AWS ECS/EKS**: Deploy v·ªõi Docker

### 3. Nginx reverse proxy:
```nginx
server {
    listen 80;
    server_name yourdomain.com;

    location / {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

## üìä Monitoring

- Health check endpoint: `/health`
- Logs: S·ª≠ d·ª•ng uvicorn/gunicorn logs
- Metrics: C√≥ th·ªÉ t√≠ch h·ª£p Prometheus/Grafana

## üîí Security

- CORS ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh
- Input validation v·ªõi Pydantic
- Error handling
- Rate limiting (c·∫ßn th√™m middleware)

## ü§ù Contributing

1. Fork repository
2. T·∫°o feature branch
3. Commit changes
4. Push v√† t·∫°o Pull Request
